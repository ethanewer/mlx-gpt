{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "from typing import Generator, Sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlx import core as mx, nn, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens are chars, so the vocab size is the number of unique chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "char2int = {c: i for i, c in enumerate(chars)}\n",
    "int2char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "\n",
    "def encode(s: str) -> list[int]:\n",
    "    return [char2int[c] for c in s if c in char2int]\n",
    "\n",
    "\n",
    "def decode(y: list[int] | np.ndarray | mx.array) -> str:\n",
    "    if isinstance(y, mx.array):\n",
    "        y = np.array(y)\n",
    "    return \"\".join([int2char[int(i)] for i in y if int(i) in int2char])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input text is encoded as an `mx.array`, then split into training and validation\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = mx.array(encode(text), dtype=mx.int64)\n",
    "\n",
    "val_size = len(full_data) // 10\n",
    "\n",
    "train_data = full_data[val_size:]\n",
    "val_data = full_data[:val_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data into blocks\n",
    "\n",
    "$x_i = [d_i, d_{i + 1}, ..., d_{i + b}]$\n",
    "\n",
    "$y_i = [d_{i + 1}, d_{i + 2}, ..., d_{i + b + 1}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_data(data: mx.array, block_size: int) -> tuple[mx.array, mx.array]:\n",
    "    n_blocks = len(data) - block_size - 1\n",
    "    x = mx.stack([data[i:i + block_size] for i in range(n_blocks)])\n",
    "    y = mx.stack([data[i:i + block_size] for i in range(1, n_blocks + 1)])\n",
    "    mx.eval(x, y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random batches for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterate(\n",
    "    x: mx.array, \n",
    "    y: mx.array, \n",
    "    batch_size: int,\n",
    ") -> Generator[tuple[mx.array, mx.array], None, None]:\n",
    "    permutation = mx.array(np.random.permutation(y.shape[0]))\n",
    "    for s in range(0, y.shape[0], batch_size):\n",
    "        idxs = permutation[s:s + batch_size]\n",
    "        bx = x[idxs]\n",
    "        by = y[idxs]\n",
    "        mx.eval(bx, by)\n",
    "        yield bx, by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Normalization\n",
    "\n",
    "$y = \\frac{x - E[x]}{\\sqrt{E[(x - E[x])^2] + \\epsilon}} \\odot \\gamma + \\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: Sequence[int], bias=True, eps=1e-5) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = mx.ones(normalized_shape)\n",
    "        self.bias = mx.ones(normalized_shape) if bias else None\n",
    "        self.eps = eps\n",
    "    \n",
    "\n",
    "    def __call__(self, x: mx.array): \n",
    "        return mx.fast.layer_norm(x, self.weight, self.bias, self.eps) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Attention\n",
    "\n",
    "$[q_{i, j}, k_{i, j}, v_{i, j}] = x_{i, j}[W_q, W_k, W_v] + [b_q, b_k, b_v]$ \n",
    "where all $q, k, v, x, b$ are row vectors\n",
    "\n",
    "$[q_{i, j}, k_{i, j}, v_{i, j}]$ are computed for $x_i$ in the 3D tensor \n",
    "$x = \\begin{bmatrix}\n",
    "x_{1, 1} & \\dots & x_{1, T} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "x_{B, 1} & \\dots & x_{B, T}\n",
    "\\end{bmatrix}$ resulting in tensors $q, k, v$\n",
    "\n",
    "$x$ has shape $(B, T, C)$ where $B$ is the batch size, $T$ is the sequence length,\n",
    "and $C$ is the number of embedding dimensions\n",
    "\n",
    "$q, k, v$ have shape $(B, T, ND)$ where $B$ is the batch size, \n",
    "$T$ is the sequence length, $N$ is the number of attention heads, and $D$ is the\n",
    "number of query/key dimensions\n",
    "\n",
    "$q, k, v$ are reshaped to $(B, N, T, D)$\n",
    "\n",
    "$a_{i, j} = q_{i, j} k_{i, j}^T$\n",
    "\n",
    "$a_{i, j} = -\\infty$ for all $i < j$\n",
    "\n",
    "$a_{i, j} = \\text{softmax}(a_{i, j})$ where softmax is computed rowwise\n",
    "\n",
    "$y_{i, j} = a_{i, j} v_{i, j}$\n",
    "\n",
    "$y$ has shape $(B, N, T, D)$\n",
    "\n",
    "$y$ is reshaped to $(B, T, ND)$, so $y_{i, j}$ is a row vector\n",
    "\n",
    "$y_{i, j} = y_{i, j}W_p + b_p$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_embed: int, n_head: int, \n",
    "        mask: mx.array, dropout: float, bias=True\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_embed = n_embed\n",
    "        self.n_head = n_head\n",
    "        assert n_embed % n_head == 0 \n",
    "        self.D = n_embed // n_head\n",
    "\n",
    "        self.c_attn = nn.Linear(n_embed, 3 * n_embed, bias=bias)\n",
    "        self.c_proj = nn.Linear(n_embed, n_embed, bias=bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.mask = mask\n",
    "        self.scale = 1.0 / np.sqrt(self.D)\n",
    "    \n",
    "\n",
    "    def __call__(self, x: mx.array):\n",
    "        B, T, n_embed = x.shape\n",
    "        assert n_embed == self.n_embed\n",
    "\n",
    "        tmp = self.c_attn(x)\n",
    "        tmp = tmp.split(self.n_embed, axis=2)\n",
    "\n",
    "        q, k, v = mx.split(self.c_attn(x), 3, axis=2)\n",
    "\n",
    "        # reshape to (B, N, T, D)\n",
    "        q = q.reshape((B, T, self.n_head, self.D)).transpose((0, 2, 1, 3)) \n",
    "        k = k.reshape((B, T, self.n_head, self.D)).transpose((0, 2, 1, 3))\n",
    "        v = v.reshape((B, T, self.n_head, self.D)).transpose((0, 2, 1, 3))\n",
    "        \n",
    "        y = mx.fast.scaled_dot_product_attention(\n",
    "            q, k, v, \n",
    "            mask=self.mask[:T, :T], \n",
    "            scale=self.scale,\n",
    "        )\n",
    "        \n",
    "        y = y.transpose((0, 2, 1, 3)).reshape((B, T, self.n_embed)) # concat head outputs \n",
    "        y = self.c_proj(y)\n",
    "        y = self.dropout(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP\n",
    "\n",
    "$x_{i, j} = x_{i, j} W_{c} + B_{c}$\n",
    "\n",
    "$y_{i, j} = x_{i, j} W_{p} + B_{p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_embed: int, dropout: float, bias=True) -> None:\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(n_embed, 4 * n_embed, bias=bias)\n",
    "        self.c_proj = nn.Linear(4 * n_embed, n_embed, bias=bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def __call__(self, x: mx.array):\n",
    "        x = nn.gelu(self.c_fc(x))\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block\n",
    "\n",
    "Composition of layer normalization, self attention, and mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_embed: int, n_head: int, \n",
    "        mask: mx.array, dropout: float, bias=True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.ln_1 = LayerNorm(n_embed, bias=bias)\n",
    "        self.attn = SelfAttention(n_embed, n_head, mask, dropout, bias)\n",
    "        self.ln_2 = LayerNorm(n_embed, bias=bias)\n",
    "        self.mlp = MLP(n_embed, dropout, bias)\n",
    "\n",
    "\n",
    "    def __call__(self, x: mx.array):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.mlp(self.ln_2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Transformer\n",
    "- Input is an array of token indexes\n",
    "- Computes token embeddings from the input\n",
    "- Computes position embeddings from the sequence $[0, 1, ..., T - 1]$\n",
    "- $x$ is the sum of the token and position embeddings\n",
    "- $x$ is forwarded through all the blocks\n",
    "- $x$ is layer normalized one more time\n",
    "- $x$ is forwarded through a linear layer to transform it from the embedding dimension \n",
    "    to the vocab size\n",
    "- If generating, $p = \\text{softmax}(x)$, and the next index is drawn from the \n",
    "    distribution $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, n_embed: int, n_head: int, block_size: int, \n",
    "        vocab_size: int, n_layer: int, dropout: float, bias=True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.wte = nn.Embedding(vocab_size, n_embed)\n",
    "        self.wpe = nn.Embedding(block_size, n_embed)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        mask = np.zeros((block_size, block_size), dtype=np.float32)\n",
    "        mask[np.tril(np.ones((block_size, block_size))) == 0] = -np.inf\n",
    "        mask = mx.array(mask)\n",
    "        \n",
    "        self.h = [Block(n_embed, n_head, mask, dropout, bias) for _ in range(n_layer)]\n",
    "        self.ln_f = LayerNorm(n_embed, bias=bias)\n",
    "\n",
    "        self.lm_head = nn.Linear(n_embed, vocab_size, bias=False)\n",
    "        self.wte.weight = self.lm_head.weight\n",
    "\n",
    "        def init_weights(_, m: nn.Module):\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Embedding):\n",
    "                m.weight = nn.init.normal(0.0, 0.02)(m.weight)\n",
    "                if hasattr(m, \"bias\") and m.bias is not None:\n",
    "                    m.bias = mx.zeros_like(m.bias)\n",
    "        \n",
    "\n",
    "        self.apply_to_modules(init_weights)\n",
    "                \n",
    "    \n",
    "\n",
    "    def __call__(self, x_idx: mx.array):\n",
    "        _, T = x_idx.shape\n",
    "\n",
    "        assert T <= self.block_size, \\\n",
    "            f\"cannot forward sequence of length {T}, block size is only {self.block_size}\"\n",
    "        \n",
    "        pos = mx.arange(0, T, dtype=mx.int64)\n",
    "\n",
    "        tok_emb = self.wte(x_idx) # shape (B, T, C)\n",
    "        pos_emb = self.wpe(pos) # shape (T, C)\n",
    "\n",
    "        # (B, T, C) + (T, C) = (B, T, C)\n",
    "        # elementwise addition for each batch\n",
    "        x = self.drop(tok_emb + pos_emb)\n",
    "        for blk in self.h:\n",
    "            x = blk(x)\n",
    "        x = self.ln_f(x)\n",
    "        x = self.lm_head(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def generate(self, x_idx: mx.array, max_new_tokens: int, temperature=1.0):\n",
    "        # Take a conditioning sequence of indices x_idx (int64 tensor of shape (B, T)) and \n",
    "        # complete the sequence max_new_tokens times, feeding the predictions back into \n",
    "        # the model each time. Most likely you\"ll want to make sure to be in model.eval() \n",
    "        # mode of operation for this.\n",
    "        for _ in range(max_new_tokens):\n",
    "            if x_idx.shape[1] <= self.block_size:\n",
    "                x_idx_cropped = x_idx \n",
    "            else:\n",
    "                x_idx_cropped = x_idx[:, -self.block_size:]\n",
    "\n",
    "            logits = self(x_idx_cropped)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            next_idx = mx.random.categorical(logits)[None]\n",
    "            x_idx = mx.concatenate((x_idx, next_idx), axis=1)\n",
    "        return x_idx  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_INTERVAL = 2500\n",
    "LOG_INTERVAL = 500\n",
    "\n",
    "BLOCK_SIZE = 32\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "DTYPE = mx.float32\n",
    "\n",
    "MAX_ITERS = 10000\n",
    "\n",
    "MAX_LR = 1e-4\n",
    "WARMUP_ITERS = 100\n",
    "LR_DECAY_ITERS = 2500\n",
    "MIN_LR = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to blocks\n",
    "\n",
    "$x_i = [d_i, d_{i + 1}, ..., d_{i + b}]$\n",
    "\n",
    "$y_i = [d_{i + 1}, d_{i + 2}, ..., d_{i + b + 1}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = block_data(train_data, BLOCK_SIZE)\n",
    "x_val, y_val = block_data(val_data, BLOCK_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model, optimizer, and training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeTransformer(\n",
    "    n_embed=640, # changed so n_embed % n_head == 0\n",
    "    n_head=4, \n",
    "    block_size=BLOCK_SIZE, \n",
    "    vocab_size=vocab_size,\n",
    "    n_layer=4, \n",
    "    dropout=0.0, \n",
    "    bias=True,\n",
    ")\n",
    "\n",
    "# model.load_weights(\"checkpoints/model.npz\")\n",
    "\n",
    "model.set_dtype(DTYPE)\n",
    "\n",
    "optimizer = optimizers.AdamW(1e-3, (0.9, 0.95), 1e-7, 0.1)\n",
    "\n",
    "state = [model.state, optimizer.state]\n",
    "\n",
    "mx.eval(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change learning rate over time\n",
    "\n",
    "$\\eta_i = \\begin{cases}\n",
    "    \\frac{\\eta \\cdot i}{N_{\\text{warmup}}} & i < N_{\\text{warmup}} \\\\\n",
    "    \\eta_{\\text{min}} + \\left(\n",
    "        \\frac{1}{2} + \\frac{1}{2}\\cos\\left(\n",
    "            \\pi \\frac{N_{\\text{warmup}} \\cdot i}{N_{\\text{decay}} - N_{\\text{warmup}}}\n",
    "        \\right)\n",
    "    \\right)(\\eta_0 - \\eta_{\\text{min}}) & N_{\\text{warmup}} \\leq i < N_{\\text{decay}} \\\\\n",
    "    \\eta_{\\text{min}} & N_{\\text{decay}} \\leq i\n",
    "\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(iter_num: int) -> float:\n",
    "    if iter_num < WARMUP_ITERS: \n",
    "        return MAX_LR * iter_num / WARMUP_ITERS \n",
    "    \n",
    "    if iter_num > LR_DECAY_ITERS:\n",
    "        return MIN_LR\n",
    "    \n",
    "    decay_ratio = (iter_num - WARMUP_ITERS) / (LR_DECAY_ITERS - WARMUP_ITERS)\n",
    "    assert 0 <= decay_ratio and decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + np.cos(np.pi * decay_ratio))\n",
    "    return MIN_LR + coeff * (MAX_LR - MIN_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([get_lr(i) for i in range(1, MAX_ITERS + 1)])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossentropy loss:\n",
    "\n",
    "$l(x, y, \\theta) = -\\sum_i y_i \\log(f(x_i, \\theta))$\n",
    "\n",
    "<br>\n",
    "\n",
    "### Train Step with Adam Optimizer\n",
    "\n",
    "$g_t = \\nabla_{\\theta_{t - 1}} l(x, y, )$\n",
    "\n",
    "$\\alpha = \\eta \\frac{\\sqrt{1 - \\beta_2^t}}{1 - \\beta_1^t}$\n",
    "\n",
    "$m_t = \\beta_1 m_{t - 1} + (1 - \\beta_1)g_t$\n",
    "\n",
    "$m_t = \\beta_2 v_{t - 1} + (1 - \\beta_2)g_t^2$\n",
    "\n",
    "$\\theta_t = \\theta_{t - 1} - \\alpha \\frac{m_t}{\\sqrt{v_t} + \\epsilon}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, y):\n",
    "    return nn.losses.cross_entropy(model(x), y, reduction=\"mean\")\n",
    "\n",
    "\n",
    "@partial(mx.compile, inputs=state, outputs=state)\n",
    "def train_step(x, y):\n",
    "    loss, grads = nn.value_and_grad(model, loss_fn)(model, x, y)\n",
    "    optimizer.update(model, grads)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@partial(mx.compile, inputs=state)\n",
    "def eval_step(x, y):\n",
    "    return loss_fn(model, x, y)\n",
    "\n",
    "\n",
    "def evaluate_loss(x, y, max_iters=100):\n",
    "    loss_sum = 0\n",
    "    cnt = 0\n",
    "    for i, (bx, by) in enumerate(batch_iterate(x, y, BATCH_SIZE)):\n",
    "        if i >= max_iters:\n",
    "            break\n",
    "        loss = eval_step(bx, by)\n",
    "        loss_sum += loss * len(x)\n",
    "        cnt += len(x)\n",
    "    loss = loss_sum / cnt\n",
    "    mx.eval(loss)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 500] loss: 2.219, time: 11.289s\n",
      "[1000] loss: 2.031, time: 11.067s\n",
      "[1500] loss: 1.844, time: 11.152s\n",
      "[2000] loss: 2.000, time: 11.149s\n",
      "[2500] loss: 1.859, time: 11.151s\n",
      "    train loss: 1.9141, val loss: 1.9297\n",
      "    saved model to checkpoints\n",
      "[3000] loss: 1.852, time: 12.429s\n",
      "[3500] loss: 1.781, time: 11.153s\n",
      "[4000] loss: 1.789, time: 11.164s\n",
      "[4500] loss: 1.859, time: 11.172s\n",
      "[5000] loss: 1.875, time: 11.162s\n",
      "    train loss: 1.8750, val loss: 1.8906\n",
      "    saved model to checkpoints\n",
      "[5500] loss: 1.781, time: 12.432s\n",
      "[6000] loss: 1.805, time: 11.154s\n",
      "[6500] loss: 1.781, time: 11.155s\n",
      "[7000] loss: 1.664, time: 11.153s\n",
      "[7500] loss: 1.906, time: 11.149s\n",
      "    train loss: 1.8516, val loss: 1.9141\n",
      "[8000] loss: 1.742, time: 12.388s\n",
      "[8500] loss: 1.734, time: 11.140s\n",
      "[9000] loss: 1.711, time: 11.141s\n",
      "[9500] loss: 1.867, time: 11.142s\n",
      "[10000] loss: 1.781, time: 11.148s\n",
      "    train loss: 1.8672, val loss: 1.9141\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "t0 = time.time()\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "while True:\n",
    "    if i > MAX_ITERS:\n",
    "        break\n",
    "     \n",
    "    for x, y in batch_iterate(x_train, y_train, batch_size=BATCH_SIZE):\n",
    "        if i > MAX_ITERS:\n",
    "            break\n",
    "        \n",
    "        optimizer.learning_rate = get_lr(i)\n",
    "\n",
    "        loss = train_step(x, y)\n",
    "        mx.eval(state)\n",
    "\n",
    "        if i % LOG_INTERVAL == 0:\n",
    "            t1 = time.time()\n",
    "            dt = t1 - t0\n",
    "            t0 = t1\n",
    "            print(f\"[{i:4}] loss: {loss.item():.3f}, time: {dt:.3f}s\")\n",
    "        \n",
    "        if i % EVAL_INTERVAL == 0:\n",
    "            train_loss = evaluate_loss(x_train, y_train)\n",
    "            val_loss = evaluate_loss(x_val, y_val)\n",
    "            print(f\"    train loss: {train_loss:.4f}, val loss: {val_loss:.4f}\")\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                model.save_weights(f\"checkpoints/model1.npz\")   \n",
    "                print(f\"    saved model to checkpoints\")\n",
    "\n",
    "        i += 1   \n",
    "\n",
    "# float32:\n",
    "# 4m 31.3s\n",
    "# train loss: 1.4603, val loss: 1.5795\n",
    "\n",
    "# bfloat16:\n",
    "# 3m 48.1s\n",
    "# train loss: 1.8359, val loss: 1.9062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.8359, val loss: 1.9062\n"
     ]
    }
   ],
   "source": [
    "train_loss = evaluate_loss(x_train, y_train)\n",
    "val_loss = evaluate_loss(x_val, y_val)\n",
    "print(f\"train loss: {train_loss:.4f}, val loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Tay the beann.\n",
      "\n",
      "HENRY VILOCK:\n",
      "Neet freing and elger-NET:\n",
      "And no fork, housh thim wear promes.\n",
      "'KINI\n"
     ]
    }
   ],
   "source": [
    "context = mx.array(encode(\"Hello, my name is\"))[None]\n",
    "output = model.generate(context, max_new_tokens=100, temperature=1)\n",
    "mx.eval(output)\n",
    "print(decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
